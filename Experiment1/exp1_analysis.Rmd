---
title: "Experiment 1 analysis"
output: html_document
---

```{r load-libraries, message = FALSE, warning = FALSE}
library(tidyverse)
library(here)
library(tidyboot)
library(lme4)
library(ggthemes)
```

### Load in file
```{r}
tidy_final <- as_tibble(read.csv(here("Experiment1/exp1_clean_final.csv")))
```

## Age calculations before exclusion
```{r age-full}
age_stats_all <- tidy_final %>%
  group_by(Subject) %>%
  summarise(age = mean(Age)) %>%
  ungroup() %>%
  summarise(m_age = mean(age), sd_age = sd(age), range =range(age))

age_stats_all

age_test_all <- tidy_final %>%
  group_by(Subject, Condition) %>%
  summarise(age = mean(Age)) 
reform_all <- age_test_all %>% 
  filter(Condition == "Reformulation") %>% 
  pull(age)
repetition_all <- age_test_all %>% 
  filter(Condition == "Repetition") %>% 
  pull(age)

t.test(reform_all,repetition_all)
```


### Calculating Lexical Error Rate Exclusion
```{r error-rates}
error_rates <- tidy_final %>%
  group_by(Subject) %>%
  summarise(Lex_Error = mean(Lex_Error == "yes")) %>%
  arrange(desc(Lex_Error))

tidy_final_sample <- tidy_final %>%
  filter(Subject != 20 & Subject != 44 & Subject != 17)

n_children_final <- n_distinct(tidy_final_sample$Subject)

age_stats <- tidy_final_sample %>%
  group_by(Subject) %>%
  summarise(age = mean(Age)) %>%
  ungroup() %>%
  summarise(m_age = mean(age), sd_age = sd(age), range =range(age))

age_stats

age_test <- tidy_final_sample %>%
  group_by(Subject, Condition) %>%
  summarise(age = mean(Age)) 
reform <- age_test %>% 
  filter(Condition == "Reformulation") %>% 
  pull(age)
repetition <- age_test %>% 
  filter(Condition == "Repetition") %>% 
  pull(age)

t.test(reform,repetition)
```

# Analyses with final sample
(excluding subjects with 20% lex error rates)

```{r}
trial_data <- tidy_final_sample %>%
  mutate(Section = factor(Section, levels = c("pre","trial1","trial2","post"), 
                          labels = c("pre", "block1","block2", "post")),
         Condition = as.factor(Condition),
         Plural_Error = as.factor(Plural_Error),
         Type = as.factor(Type),
         Lex_Error = as.factor(Lex_Error)) %>%
  filter(Lex_Error == "no") %>%
  filter(!is.na(Plural_Error)) %>%
  filter(Type == "IP") %>%
  droplevels()
```

### Bootstrap mean error rates for each trial type across conditions
```{r bootstrap-descriptives}
boot_all <- trial_data %>%
  filter(!is.na(Plural_Error)) %>%
  group_by(Condition, Section, Subject) %>%
  summarise(Plural_Error= mean(Plural_Error == "yes")) %>%
  tidyboot_mean(Plural_Error)

boot_all
```

```{r plot-condition}
ggplot(boot_all, aes(x=Section, y=empirical_stat, fill=Condition)) +
  geom_col(position = position_dodge(.5),
           width = .5) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper),
                 position=position_dodge(.5)) +
  ylab("Pluralization Errors (prop.)") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.position = "top") +
  xlab("") +
  scale_fill_manual(values = c("#D66252", "#87BFBF")) +
  theme(axis.text=element_text(size=12),
        axis.title=element_text(size=14),
        legend.text = element_text(size=12),
        legend.title = element_text(size=14),
        plot.title = element_text(size=16))
```

### Interaction Model
```{r}
pre_post <- trial_data %>%
  filter(Section == "pre" | Section == "post") %>%
  droplevels()
```

```{r}
contrasts(pre_post$Condition) <- c(-0.5,0.5)
contrasts(pre_post$Section) <- c(-0.5,0.5)

lmer <- glmer(Plural_Error ~ Condition * Section
                       + (1 | Subject) + (1 | target),
                       family = "binomial", data = pre_post) 
summary(lmer)
```

## Comparing Pretest error rates
```{r pre-comparison-model}
contrasts(trial_data$Condition) <- c(-0.5,0.5)

compare_pre <- glmer(Plural_Error ~ Condition + (1 | Subject) + (1 + Condition|target),  
                             family = "binomial", 
                             data = trial_data %>% 
                               filter(Section == "pre")) 
summary(compare_pre)
```

## Modelling reformulation performance on all trials to pretest
```{r reform-all-trials-model}
reformulation_model <- glmer(Plural_Error ~ Section + (1 | Subject) + (1 |target),  
                             family = "binomial", 
                             data = trial_data %>% 
                               filter(Condition == "Reformulation")) 
summary(reformulation_model)
```

## Modelling repetition performance on all trials to pretest
```{r repetition-all-trials-model}
repetition_model <- glmer(Plural_Error ~ Section + (1 | Subject) + (1|target), 
                             family = "binomial", 
                             data = trial_data %>% 
                               filter(Condition == "Repetition")) 

summary(repetition_model)
```

### Model predicting performance by condition and pretest performance
```{r overall-learning}
pre_post_matched <- pre_post %>%
  select(Subject, Condition, Section, Type, Plural_Error, target) %>%
  group_by(Subject, target) %>%
  pivot_wider(names_from = Section, values_from = Plural_Error)

pre_to_post <- glmer(post ~ pre + Condition + (1|Subject) + (1 + Condition|target),
                     family = "binomial", data = pre_post_matched)

summary(pre_to_post)
```
