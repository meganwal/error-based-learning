---
title: "Experiment 2 Analysis"
output: html_document
date: "2023-10-06"
---

```{r load-libraries, message = FALSE, warning = FALSE}
library(tidyverse)
library(here)
library(tidyboot)
library(lme4)
library(ggthemes)
```

### Load File

```{r}
tidy_final_2 <- read.csv(here("Experiment2/exp2_clean_final.csv"))
```

### Calculating Lexical Error Rate Exclusion
```{r}
error_rates_2 <- tidy_final_2 %>%
  group_by(Subject) %>%
  summarise(Lex_Error = mean(Lex_Error == "yes")) %>%
  arrange(desc(Lex_Error))

tidy_final_sample_2 <- tidy_final_2 %>%
  filter(Subject != 23)

age_test_2 <- tidy_final_sample_2 %>%
  group_by(Subject) %>%
  summarise(age = mean(Age_Y)) %>%
  arrange(desc(Subject)) %>%
  ungroup() %>%
  summarise(m_age = mean(age), sd_age = sd(age))
```

# Analyses with final sample
(excluding subject with 20% lex error rates)

```{r}
trial_data_2 <- tidy_final_sample_2 %>%
  mutate(Section = factor(Section,levels=c("pre", "trial1","trial2", "post"), 
                          labels = c("pre", "block1","block2", "post")),
         Condition = factor(Condition, levels = c("Reformulation", "Repetition")),
         Plural_Error = factor(Plural_Error, levels = c("no", "yes")),
         Type = as.factor(Type),
         Lex_Error = as.factor(Lex_Error)) %>%
  filter(!is.na(Plural_Error)) %>%
  filter(Lex_Error == "no") %>%
  filter(Type == "IP") %>%
  droplevels()
```

### Bootstrap mean error rates for each trial type across conditions
```{r bootstrap}
boot_all_referent <- trial_data_2 %>%
  group_by(Condition, Section, Subject) %>%
  summarise(Plural_Error= mean(Plural_Error=="yes")) %>%
  tidyboot_mean(Plural_Error, na.rm = TRUE) %>%
  filter(Condition != "NA") %>%
  filter(Section != "NA")
```

```{r plot}
ggplot(boot_all_referent, aes(x=Section, y=empirical_stat, fill=Condition)) +
  geom_col(position = position_dodge(.5),
           width = .5) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper), 
                 position=position_dodge(.5)) +
  ylab("Overregularization Errors (prop.)") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        panel.background = element_blank(), axis.line = element_line(colour = "black"),
        legend.position = "top") + 
  xlab("") +
  scale_fill_manual(values = c("#D66252", "#87BFBF"))
```
### Interaction Model
```{r}
pre_post_2 <- trial_data_2 %>%
  filter(Section %in% c("pre", "post")) %>%
  mutate(Section = factor(Section, levels = c("pre","post"))) %>%
  droplevels()

overall_model_2 <- pre_post_2 %>%
  glmer(Plural_Error ~ Section * Condition 
                       + (1 | Subject) + (1 + Condition | Target),
                       family = "binomial", data = .) 
summary(overall_model_2)
```

## Comparing Pretest error rates
```{r pre-models}
contrasts(trial_data_2$Condition) <- c(-0.5,0.5)

compare_pre_2 <- glmer(Plural_Error ~ Condition + (1 | Subject) + (1|Target),  
                             family = "binomial", 
                             data = trial_data_2 %>% 
                               filter(Section == "pre")) 

summary(compare_pre_2)
```

## Modelling reformulation performance on all trials to pretest
```{r reform-all-trials}
reformulation_model_2 <- glmer(Plural_Error ~ Section + (1 | Subject) + (1| Target),  
                             family = "binomial", 
                             data = trial_data_2 %>% 
                               filter(Condition == "Reformulation")) 

summary(reformulation_model_2)
```
## Modelling repetition performance on all trials to pretest
```{r repetition-all-trials}
repetition_model_2 <- glmer(Plural_Error ~ Section + (1 | Subject) + (1|Target), 
                             family = "binomial", 
                             data = trial_data_2 %>% 
                               filter(Condition == "Repetition"))

summary(repetition_model_2)
```

### Model predicting performance by condition and pretest performance
```{r overall model}
pre_post_matched_2 <- pre_post_2 %>%
  select(Subject, Condition, Section, Type, Plural_Error, Target) %>%
  group_by(Subject, Target) %>%
  pivot_wider(names_from = Section, values_from = Plural_Error)

pre_to_post_2 <- glmer(post ~ pre + Condition + (Condition|Subject) + (1|Target),
                     family = "binomial", data = pre_post_matched_2)

pre_to_post_2 %>% summary()
```

### Change in error from pre to post by word
```{r}
ref_word_analyses <- tidy_final_2 %>%
  filter(Plural_Error != "NA") %>%
  filter(Type == "IP") %>%
  mutate(Section = factor(Section,levels=c("pre", "trial1","trial2", "post"), labels = c("pre", "block1","block2", "post"))) %>%
  group_by(Target) %>%
  filter(Lex_Error == "no", Section == "pre" | Section == "post") %>%
  select(Target, Plural_Error, Section, Condition, Subject) %>%
  group_by(Section, Target, Condition) %>%
  summarise(Plural_Error= mean(Plural_Error=="yes")) %>%
  group_by(Target) %>%
  pivot_wider(names_from = Section, values_from = Plural_Error) %>%
  mutate(Change = post - pre)
```

### Comparing performance across counterbalanced groups
```{r order comparisons}
boot_all_referent_group <- trial_data_2 %>%
  group_by(Condition, Group, Section, Type, Subject) %>%
  filter(Lex_Error == "no") %>%
  summarise(Plural_Error= mean(Plural_Error=="yes")) %>%
  tidyboot_mean(Plural_Error) %>%
  filter(Condition != "NA") %>%
  filter(Section != "NA")
```

```{r}
ggplot(boot_all_referent_group, aes(x=Section, y=empirical_stat, fill=Condition, color = Group)) +
  geom_col(position = position_dodge(.5),
           width = .5) +
  geom_linerange(aes(ymin=ci_lower, ymax=ci_upper),
                 position=position_dodge(.5)) +
  ylab("Proportion of Errors") +
  theme(legend.position = "top") +
  xlab("")+
  scale_fill_manual(values=c("skyblue4", "gray"))
```
